{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0bdcd3-e35f-4843-8c1c-499039528d48",
   "metadata": {},
   "source": [
    "## Data Engineering for Everyone\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c32f9e-0048-4ae8-9f75-819068a7e83a",
   "metadata": {},
   "source": [
    "## Course Description\n",
    "\n",
    "In 2019, the average salary for data engineers overtook data scientists. How did this happen? Companies wanting to find the gold within their data realized it wasn’t possible if they hadn’t yet built the mine. Data engineers lay the foundations that make data science possible.\n",
    "\n",
    "In this course, you’ll learn about a data engineer’s core responsibilities, how they differ from data scientists, and facilitate the flow of data through an organization. Through hands-on exercises you’ll follow Spotflix, a fictional music streaming company, to understand how their data engineers collect, clean, and catalog their data. By the end of the course, you’ll understand what your company's data engineers do, be ready to have a conversation with a data engineer, and have a solid foundation to start your own data engineer journey. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ea6e9-9934-497c-8302-ca87e95f88e3",
   "metadata": {},
   "source": [
    "##  What is data engineering?\n",
    "Free\n",
    "0%\n",
    "\n",
    "In this chapter, you’ll learn what data engineering is and why demand for them is increasing. You’ll then discover where data engineering sits in relation to the data science lifecycle, how data engineers differ from data scientists, and have an introduction to your first complete data pipeline.\n",
    "\n",
    "    Data engineering and big data    50 xp\n",
    "    Go with the flow    100 xp\n",
    "    Not responsible    100 xp\n",
    "    Big time    100 xp\n",
    "    Data engineers vs. data scientists    50 xp\n",
    "    Tell me the truth    50 xp\n",
    "    Who is it    100 xp\n",
    "    The data pipeline    50 xp\n",
    "    It's not true    50 xp\n",
    "    Pipeline    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6effdcb5-ffe1-4a5e-9ba3-c36564b7ba57",
   "metadata": {},
   "source": [
    "##  Storing data\n",
    "Free\n",
    "0%\n",
    "\n",
    "It’s time to talk about data storage—one of the main responsibilities for a data engineer. In this chapter, you’ll learn how data engineers manage different data structures, work in SQL—the programming language of choice for querying and storing data, and implement appropriate data storage solutions with data lakes and data warehouses.\n",
    "\n",
    "    Data structures    50 xp\n",
    "    Structures    50 xp\n",
    "    What's the difference    100 xp\n",
    "    SQL databases    50 xp\n",
    "    We can work it out    50 xp\n",
    "    Columns    50 xp\n",
    "    Different breeds    100 xp\n",
    "    Data warehouses and data lakes    50 xp\n",
    "    Tell the truth    50 xp\n",
    "    Our warehouse (in the middle of our street)    100 xp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fd570-3fc5-4ae0-86fc-caa6b0dfa5e5",
   "metadata": {},
   "source": [
    "##  Moving and processing data\n",
    "Free\n",
    "0%\n",
    "\n",
    "Data engineers make life easy for data scientists by preparing raw data for analysis using different processing techniques at different steps. These steps need to be combined to create pipelines, which is when automation comes into play. Finally, data engineers use parallel and cloud computing to keep pipelines flowing smoothly.\n",
    "\n",
    "    Processing data    50 xp\n",
    "    Connect the dots    100 xp\n",
    "    Scheduling data    50 xp\n",
    "    Schedules    100 xp\n",
    "    One or the other    100 xp\n",
    "    Parallel computing    50 xp\n",
    "    Whenever, whenever    50 xp\n",
    "    Parallel universe    100 xp\n",
    "    Cloud computing    50 xp\n",
    "    Obscured by clouds    100 xp\n",
    "    Somewhere I belong    100 xp\n",
    "    We are the champions    50 xp \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d10a95-a89a-4124-a4a3-af3d10575bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c890bd7d-d81c-40d9-9ad3-4238b88aea62",
   "metadata": {},
   "source": [
    "## Data engineering and big data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Welcome to Data Engineering for everyone.  My name is Hadrien, and I will be your instructor for this course.  This is a conceptual course; there is no code involved.  \n",
    "\n",
    "If you are not a developer, the objective is to provide you with a solid enough understanding of the topic so that you can exchange with and understand data engineering team.  If you are interested in actually developing data engineering projects, the objective is to equip you with conceptual knowledge allowing you to get the most out of our data engineering curriculum.  \n",
    "\n",
    "This first chapter will clarify what Data Engineering is; specifically, how it relates to big data and how a data engineer differ from a data scientist.  Data Engineers build data pipelines, so we will end this chapter by looking into these as well.  \n",
    "\n",
    "Building on these foundations, in the second chapter, we will then take things in order.  We will study data storage: the different types of data structures, the central role that the SQL langurage plays in data engineering, and some storage solutions.  \n",
    "\n",
    "Once data is stored, it is ready to be processed.  This will be the topic of the third chapter, where we will dive deeper into processing methods and tools, scheduling, parallel computing and cloud computing.  \n",
    "\n",
    "\n",
    "Throughout the course, we will look at how all these data engineering concepts are implemented at a fictional music streaming company named Spotflix.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Lets take things from the start then.  There are 4 general steps through which data flows within an organization.  First, we collect and ingest the data, from web traffic, surveys, or media consumption for example.  Data is stored in raw format.  The next step is to prepare it, whcih includes \"cleaning data\", for instance finding missing or duplicate values, and converting data into a more organized format.  Once the data is clean and organized, it can be exploited.  We explore it, visualize it, build dashboards to track changes or compare two set of data.  Finally, once we have a good grasp of our data, we're ready to run experiments, like evaluate which article title gets the most hits, or to build predictive models, for example to forcast stock prices.  \n",
    "# *******************************************************************************************************************\n",
    "\n",
    "[Data Collection & Storage ---> Data Preparation ---> Exploration & Visualization ---> Experimentation & Prediction]\n",
    "\n",
    "# Data engineers are responsible for the first step of the process: \n",
    "ingesting collected data and storing it.  They have a great responsibility as they lay the ground work for data analysts, data scientist and machine learning engineers.  If the data is scattered around, corrupted, and diffcult to access, there is not much to prepare, explore, or experiment with.  And thats exactly why you need a Data Engineer: their job is to deliver the correct data, in the right form, to the right people, as efficiently as possible.  They ingest data from different sources, optimize the databases for analysis, and manage data corruption.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Data engineers develop, construct, test, and maintain architectures such as databases and large-scale processing systems to process and handle massive amounts of data.  If you are not sure what this all means, thats okay.  The course will unpackll this jargon and explain the what, why and how.  \n",
    "\n",
    "With the advent of big data, the demand for data engineers has increased.  Big data can be defined as data so large you have to think about how to deal with its size, because its difficult to process using traditional data management methods.  The graph helps make sense of the growth of big data.  In order of volume, big data is mainly composed of sensors and devices data, social media data, enterprise data and VoIP data.  \n",
    "\n",
    "Big data is commonly characterized by 5 Vs.  [Volume] (the quantity of data points), [Variety] (type and nature of the data: text, image, video, audio), [Velocity] (how fast the data is generated and processed), [Veracity] (how trustworthy the sources are), and [Value] (how actionable the data is).  Data engineers need to take all of this into consideration.  \n",
    "\n",
    "\n",
    "Already, Now you not only know what's waiting for you in this course, but also how data flows with in an organization, when a data engineer intervenes, what their responsibilities are, and how they relate to big data.  Lets check your understanding.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e2f25-c087-4988-94e6-65c60d71c3fe",
   "metadata": {},
   "source": [
    "## Go with the flow\n",
    "\n",
    "To understand what data engineers do, why they are necessary and the impact they have, you need to know how data flows through an organization.\n",
    "\n",
    "Can you order the four steps of the data science workflow chronologically?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Order the steps on chronologically (the step happening first should be at the top and the step happening last at the bottom)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae10c7-2275-4162-af10-bbc372bc6244",
   "metadata": {},
   "source": [
    "Data collection and storage\n",
    "\n",
    "Data preparation\n",
    "\n",
    "Exploration and visualization\n",
    "\n",
    "Experimentation and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628aaa19-ab42-4240-acdc-831372351d40",
   "metadata": {},
   "source": [
    "## Not responsible\n",
    "\n",
    "You recently joined the data science team as a manager for a music streaming company named Spotflix. It's a music platform that lets users stream songs, create playlists, follow artists, watch music videos and even look up lyrics!\n",
    "\n",
    "One of your colleagues just walked to your desk. They just got hired, but they already know you're on the data team - after training with DataCamp, you've made a name for yourself pretty quick! They have a bunch of data tasks they need completed, and they want to make sure they ask the right person. You tell them you can help them identify what they should request from data engineers, and what they should not.\n",
    "\n",
    "Can you deliver on this promise?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Here are several tasks related to working with data. Classify them in two buckets: one for data engineering tasks, one for tasks that are not the responsibility of data engineers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df334fa-d0ec-4d30-8fc7-c5e1db05fb22",
   "metadata": {},
   "source": [
    "Data engineering tasks:\n",
    "    Ensuring corrupte, unreadable music tracks are removed and dont end up facing customers\n",
    "    Optimizing the customers databases for analysis\n",
    "    Gathering music consumption data from desktop and mobile sources\n",
    "    \n",
    "    \n",
    "Not data engineering tasks:\n",
    "    Running an experiment to identify the optimal search bar positioning in the app\n",
    "    Building a visualization to understand listening patterns by city\n",
    "    Based on their listening behavior, predict which songs customers are likely to enjoy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c4818-de2e-42cd-a87d-9bf60e17b671",
   "metadata": {},
   "source": [
    "## Big time\n",
    "\n",
    "You saw how the advent of big data increased the demand for data engineers. As more data gets generated, at a higher rate, with a growing variety of formats, the need for people able to manage this data is soaring.\n",
    "\n",
    "Which of the following statements are true, and which are false?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements as either true of false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e894ad-f094-4696-8ce1-1f2af0ab0de5",
   "metadata": {},
   "source": [
    "True:\n",
    "    Value refers to how actionable the data is\n",
    "    Data types refer to the variety of data\n",
    "    \n",
    "    \n",
    "False:\n",
    "    Veracity refers to how frequently the datais generated\n",
    "    Velocity refers to how big the data is\n",
    "    Valume has to do with how trustworthy the data is\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24eaac-4a8d-4140-984c-e90413bd9612",
   "metadata": {},
   "source": [
    "## Data engineers vs. data scientists\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  In the previous lesson we got acquainted with how the data flows through an organization, focusedon the data engineers's responsibilities, and quickly mentioned data scientists.  \n",
    "\n",
    "|Data Engineer ----------|      |Data Scientist -------------------------------------------------------------------|\n",
    "[Data Collection & Storage ---> Data Preparation ---> Exploration & Visualization ---> Experimentation & Prediction]\n",
    "\n",
    "To prevent the confusion and assumptions that comes with buzzwords, lets clarify how data engineers and data scientists contrast and compare.  You already know that [data engineers] focus on the first part of the workflow.  Their role is to ingest and store the data so its easily accessible and ready to be analyzed.  [Data scientist] intervene on the rest of the workflow: they prepare the data according to their analysis needs, explore it, build insightful visualizations, and then run experiments or build predictive models.  Data engineers lay the groundwork that makes data science activity possible.  Lets see how data engineers enable data scientists.  \n",
    "\n",
    "Vivian is a [data engineer] at Spotflix, our music streaming company, and Julian is a [data scientist].  Data engineers ingest and store collected data, so that data scientist can exploit it.  \n",
    "# *******************************************************************************************************************\n",
    "Data engineers ensure that databases are optimizaed for analysis (correct table structure, information easy to retrieve) while data scientists access the databases to exploit the data it contains.  At Spotflix, Vivian makes sure that Julian can easily access tracks, artist, listening sessions data, and can analyze it without too much preparation work.  Data engineers build data pipelines.  The next lesson is focused on this topic.  Data scientist use the pipelines' outputs.  At Spotflix, Vivian builds the pipeline that pulls listening sessions data, so that Julian's analyses remain up to date.  \n",
    "\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Based on above, it's no surprise that [data engineers are software experts, while data scientists are analytics experts].  In general, Vivian uses the languages like software-oriented Python or Java, and SQL to create, update and transform databases, while Julian uses the analytics-oriented Python or R, and SQL to query or in other words, request information from databases.  \n",
    "\n",
    "\n",
    "\n",
    "Now you understand at which stages data engineers and data scientists intervene, and how data engineers enable data scientists.  Time for a sanity check.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8d8dc-9ba0-4f73-b00c-0277d5c2db7c",
   "metadata": {},
   "source": [
    "## Tell me the truth\n",
    "\n",
    "In 2012, IBM declared that 90% of the data in the world had been created in the past 2 years. That same year, the amount of digital data in the world first exceeded 1 zetabyte (1 billion terabytes). In 2020, we're expected to reach 44 zetabytes. This big data era led to the advent of two new roles: data engineers and data scientists. You just studied the differences between these two roles.\n",
    "\n",
    "Let's have a quick sanity check: which of the following options is true?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Data engineers intervene at the very end of the data workflow.\n",
    "    1\n",
    "    Data scientists build pipelines.\n",
    "    2\n",
    "    Data engineers need strong statistical expertise.\n",
    "    3\n",
    "#    Data engineers enable data scientists.\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320f38b-035f-439f-97cf-acf84b759610",
   "metadata": {},
   "source": [
    "## Who is it\n",
    "\n",
    "In the first lesson, you classified some data related tasks between data engineer tasks and not data engineer tasks. Let's raise the bar and see if you can assign more specific tasks to data engineers or data scientists.\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Assign the tasks to the data engineer or the data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc077e5a-6fc1-4c73-8d9c-7e2ffaaef127",
   "metadata": {},
   "source": [
    "Data engineer:\n",
    "    Ensure that people who use the databases can't erase music videos by mistake\n",
    "    Use Java to build a pipeline collecting album covers and storing them\n",
    "    Provide listening sessions data so it can be analyzed with minimal preparation work\n",
    "    \n",
    "    \n",
    "Data scientist:\n",
    "    Identify which customers are likely to end their Spotflix subscriptions, so marketing can target them and encourage them to renew\n",
    "    Use Python to run an analysis on wheather users prefex having the search bar on the top left or the top right of the Spotflix desktopapp\n",
    "    Find out in which countries certain artists are popular to give them insights on where to tour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee189404-7881-48c5-9a28-376408ccdb94",
   "metadata": {},
   "source": [
    "## The data pipeline\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Alright, we've mentioned the term pipeline several times by now, so lets focus on it for this lesson.  You may have heard the [data is new oil], as first coined by the economist, so lets follow this idea.  We extract crude oil from an oil field.  We moved the crude oil to a distillation unit, where we separate the oil into several products.  Some products are sent directly to their final users.  For example, some pipes go straight to airports to deliver kerosene.  Other products, like gasoline, are sent to gas storage facilities and stored in big tanks, before being distributed to gas stations.  Other products, like naphtha, go through several chemical transformations to create synthetic polymers for example.  Manufactures use synthetic polymers to create new products, like CDs.  \n",
    "\n",
    "As you can see, we have many pipelines trying it all together.  CDs, Ss last century, Vivian thinks.  However, to manager data for Spotflix, she follows a procedure similar to oil processing.  Companies ingest data from many different sources, which needs to be processed and stored in various ways.  To handle that, we need [data pipelines] that efficiently automate the flow from one station to the next, so that data scientists can use up-to-date, accurate, relevant data.  This isn't a simple task and thats's why data engineers are so important.  \n",
    "\n",
    "At Spotflix, we have sources from which we extract data.  For example, the users' actions and listening history on the mobile Spotflix app and desktop Spotflix app, and the Spotflix website itself.  We also have website Spotflix uses internally, like their HR management system for payroll and benefits.  The data is ingested into Spotflix system, moving from their respective sources to our data lake (no fear, we will talk about data lakes in the next chapter).  These are our first three pipelines.  \n",
    "\n",
    "We then organize the data, moving it into databases (we will talk more about databases in chapter 2 as well).  It could be [artist data], like name, number of followers, and associated acts, [albums data], like label, producer, year of release, [tracks data], like name, length, featured artists, and number of listens, [playlists data], like name, song it contains, and date of creation, [customer data], like username, account opening date, subscription tier, or [employees data], like name, salary, reporting manager, updated by human resources.  These are 6 new pipelines.  \n",
    "\n",
    "Some albums data can be extracted and stored directly.  For example, album cover pictures all have the same format, so we can store them directly without having to crop them.  That is one more pipeline.  \n",
    "\n",
    "Employees could be split in different tables by department, for example, sales, engineering, support, etc. (we will talk about tables in chapter 2 as well).  For now, that's 3 more pipelines.  These tables could be further split by offices, for example, US, Belgium, and UK.  If data scientists has to analyze employee data (to investigate employee turnover for example), this is the data they would use.  And three is anothet 3 more pipelines for each department.  \n",
    "\n",
    "Tracks would need to be processed, first to check if the track is readable, then to check if the corresponding artist is in the database, to make sure the file is in the correct size and format, etc.  Thats 1 more pipeline, that we will unpack into chapter 3 when we will talk about ata processing.  The data can then be stored in a new, clean tracks database.  this is one of the databases data scientists could use to build a recommendation engine by analyzing songs for similarity, for example.  And thats our last pipeline.  \n",
    "\n",
    "\n",
    "                                                      / US\n",
    "                                        / sales dept -- UK\n",
    "                                       /             \\ Belgium\n",
    "Phone app  \\               / employees -- engineering dept\n",
    "            \\             /            \\ support dept\n",
    "             \\           / / customers\n",
    "              \\         // / playlists\n",
    "Desktop app -- Data lake --- tracks    -- -- -- -- \n",
    "              /              albums    -- album pictures\n",
    "             /               artists\n",
    "Website     /\n",
    "\n",
    "\n",
    "In a nutshell, data pipelines ensures the data flows efficiently through the organization.  They automate extracting, transforming, combining, validating, and loading data, to reduce human intervention and errors, and decrease the time it takes for data to flow through the organization.  Dont worray, we'll cover this in detail in the last chapter.  One term you will hear a lot is [ETL].  Its a popular framework for designing data pipelines.  It breaks the flow of data into 3 sequential steps: first [Extracting data], then [Tranforming data], and finally [Loading to new database].  The key here is that data processed before its stored.  In general, data pipelines move data from one systemto another.  They may follow ETL, but not all the time.  For instance, the data may not be transformed, and routed directly to applications like visualization tools or Salesforce.  \n",
    "\n",
    "\n",
    "\n",
    "Okay, now you understand  a data pipeline is, what its used for, why its important, how we use them at Spotflix, and hwere ETL fits in.  Lets solidify your understanding of data pipelines with a couple exercises, and then onwards to chapter 2 to dive into the details of data storage.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22c749-9f9a-4a5d-b79b-5602ea2e01d8",
   "metadata": {},
   "source": [
    "## It's not true\n",
    "\n",
    "The main objective, when setting up data pipelines, is to improve the efficiency with which data flows, from its ingestion to the final users.\n",
    "\n",
    "Most of the options below are true, but one is false. Which one is it?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Data pipelines ensure an efficient flow of the data through the organization.\n",
    "    1\n",
    "    Data pipelines automate data extraction.\n",
    "    2\n",
    "#    Data pipelines necessarily include a transformation step.\n",
    "    3\n",
    "    ETL stands for Extract, Transform, Load.\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4be68-dd39-43c8-b8a3-7fc268f18ce8",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "Once you've successfully completed this exercise, make sure to read the success message! 🎶😉\n",
    "\n",
    "You've just seen some examples of pipelines used at Spotflix. Let's have you build one!\n",
    "\n",
    "Our data engineer, Vivian, is working on building new pipelines to generate a new product: the Weekly Playlist. It's a playlist that is created by our system every day to recommend new songs that users might like based on their tastes.\n",
    "\n",
    "In this exercise, you will find some steps. Can you order the steps correctly to help her build the pipeline generating a Weekly Playlist for each user? Let's start with one user, and build a pipeline to generate a Weekly Playlist for Julian, our data scientist.\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Order the steps chronologically (the step happening first should be at the top and the step happening last at the bottom).\n",
    "\n",
    "Hint\n",
    "\n",
    "    You need to know Julian's tastes before anything.\n",
    "    You then need to find users with similar tastes.\n",
    "    Once this is done, you can find the songs these users listen to that Julian might like.\n",
    "    You need to load these songs in a table: that will be the playlist we will recommend to Julian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47a1f6-5463-423a-8f55-9ea94be814bb",
   "metadata": {},
   "source": [
    "Extract the songs Julian listened to the most over the past month\n",
    "\n",
    "Find other users who listened to these same songs a lot as well\n",
    "\n",
    "    Extract only songs these other users listen to that are of the same genre as the ones in Julia's listening session.  There are our recommendations\n",
    "    ||\n",
    "    Load only the 10 top songs these users listened to the most over the past week into a table called \"Similar profiles\"\n",
    "\n",
    "Load the recommended songs into a new table.  Thats Julian's weekly playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da43b857-c009-45cc-817c-00a0459f57c3",
   "metadata": {},
   "source": [
    "## Data structures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Awesome job on chapter 1.  Lets continue our exploration of the world of data engineering.  This second chapter will focus on storage.  In this lesson, we're going to learn more about data structure.  Structured data is easy to search and organize.  Data is entered following a rigid structure, like a spreadsheet where there are set columns.  Each column takes values of a certain type, like text, data, or decimal.  It makes it easy to form relations, hence its organized in what is called a relational database.  About 20% of the data is structured.  SQL which stands for Structured Query Langurage, is used to query such data.  \n",
    "\n",
    "Here is an example of structured data. (slide shows a DF table).  This is an extract of Spotflix's employee table (index, last_name, first_name, role, team, full_time, office).  Its easy to read the table and well-organized.  You can see it follows a model: each row expects an employee and each column a specific information about that employee.  Each column needs to be of a certain type.  The index is a number, and acts as a unique ID, becuase 2 employee may have the same name, role and office.  The penultimate column holds logical values: values can only be true or false.  For example,  Rick Sanchez is part-time.  The rest of the columns are text.  \n",
    "\n",
    "Because its [structured] we can easily relate this table to other structured data.  For example, if there is another table holding information about offices, we can connect on the office column.  Tables that can be connected that way from a [relational database].  [Semi-structured data] resembles structured data, but allows more freedom.  Its therefore relatively easy to organize, and pretty structured, but allows more flexibility.  It also has different types and can be grouped to form relations, although this is not as straightforward as with structured data - you have to pay for that flexibility at some point.  \n",
    "\n",
    "Semi-structured data is stored in NoSQL databases (as opposed to SQL) and usually leverages the JSON, XML or YAML file formats.  Below is an example of a JSON file storing favorite artists of each Spotflix user.  As you can see, the model is consistent: each user id contains the user's last name and first name, and their favorite artists.  However, the number of favorite artists may differ: I have 4, Sara has 2 and Lis has 3 favorite artists.  \n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Relational databases dont allow that kind of flexibility, but [semi-structured formats let you do it].  Unstructed data is the data that does not follow a model and can't be contained in a rows and columns format.  This makes it difficult to search and organize.  Its usually text, sounds, pictures or video.  Its usually stored in data lakes, althoughit can also appear in data warehouses or databases - don't worry, we will cover the difference between these at the end of this chapter.  \n",
    "\n",
    "\n",
    "{\n",
    "{\"user_1645156\": {\n",
    "    \"last_name\": \"Lacroix\", \n",
    "    \"first_name\": \"Hadrien\", \n",
    "    \"favorite_artists\": [\"Fools in Deed\", \"Gojira\", \"Pain\", \"Nanowar of Stell\"]}\n",
    "    },\n",
    "{\"user_5913764\": {\n",
    "    \"last_name\": \"Billen\", \n",
    "    \"first_name\": \"Sara\", \n",
    "    \"favorite_artists\": [\"Tamino\", \"Taylor Swift\"]}\n",
    "    }, \n",
    "    ......\n",
    "}\n",
    "\n",
    "\n",
    "# Most of the data around us is unstructed.  \n",
    "Unstructed data can be extremely valuable, but because its hard to search and organize, this value could not be extracted untill recently, with the advent of machine learning and artificial intelligence.  At Spotflix, unstructed data consists in lyrics, songs, albums picture and artists profile pictures, and music videos.  At Spotflix, we could use machine learning algorithms to parse song spectrums, analyze beats per minutes, chord progressions, genres to help categorize songs.  Or, we could have artists give additional informati when they upload their songs.  Having them add the genre, and some tags, would make it semi-structured data, and would make searching and organizing easier.  \n",
    "\n",
    "\n",
    "Alright, now you know what is characteristic of [structured data], [semi-structured data] and [unstructured data], the difference between the 3, and you're able to give examples for each of them.  Lets consolidate this knowlege with some exercises.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c302b-2d21-479d-929f-9460854580f3",
   "metadata": {},
   "source": [
    "## Structures\n",
    "\n",
    "In the video, you learned about the three different types of data structure. The less structured the data, the more flexibility there is in how it's stored.\n",
    "\n",
    "Which of the following statements is false?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    Structured data is easier to search because values are separated and organized into columns.\n",
    "    1\n",
    "    Semi-structured data allows some flexibility that structured data doesn't: different observations have different sizes.\n",
    "    2\n",
    "#    Structured data makes it harder to draw relationships with other data tables.\n",
    "    3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562839f-b21f-423f-a293-0d57d05974e9",
   "metadata": {},
   "source": [
    "## What's the difference\n",
    "\n",
    "You've just learned that data can exist in different structures. Can you correctly define structured, semi-structured and unstructured data?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements to the data structure they correspond to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59ee33-0660-4e0c-9d3b-7b3f96f53dee",
   "metadata": {},
   "source": [
    "Structured:\n",
    "    Is easy to search and organize\n",
    "    Is created and queried using SQL\n",
    "    Corresponds to data in tabular cormat\n",
    "    \n",
    "Semi-structured:\n",
    "    Follows a model while allowing more flexibility than structured data\n",
    "    Is moderately easy to search and organize\n",
    "    Is stored in XML or JSON format, or in NoSQL databases\n",
    "    \n",
    "Unstructured:\n",
    "    Is usually stored in data lake\n",
    "    Is difficult to search and organize\n",
    "    Stores images, pictures, videos and text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168ba0b-2528-4131-86e3-51c5dd3391be",
   "metadata": {},
   "source": [
    "## SQL databases\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  Lets pursue.  We've mentioned SQL several times by now, so how about we spend a bit more time on this langurage that is so fundamental in data engineering.  \n",
    "\n",
    "SQL stands for Structured Query Language.  SQL is to databases what English is to pop music.  Its the preferred langurage to query RDBMS or Relational Database Management System - sically systems that gather several tabels like Employee table from the previous lesson, where all tables are related to each other.  More on that in a moment.  \n",
    "\n",
    "SQL has 2 main advantagesL it allows you to access many records at once, and group, filter or aggregate them.  Most programming langurage let you do that, but SQL was the first, which is why its been so influential.  Its a little bit like the Beatles and pop music.  Its also very close to English, which makes it easy to write and understand.  As you already know data engineers use SQL to create maintain databases, while data scientists use SQL to query databases.  We're not going to learn SQL in this course, not test you on it: we have great courses and tracks that covers this topic.  However, looking at some examples will help you understanding.  \n",
    "\n",
    "# Lets look at a data engineering example first, [creating a table].  \n",
    "Take a moment to refresh your memory of Spotflix exmplyee table.  Remember the first column holds non-decimal numbers, the penultimate one store logic value, and the others hold text.  We can create such a table using SQL.  We type the command [CREAT TABEL], and declare the name of the table, \"employees\", then we proceed to create the first column, [employee_id], and specify the type of data expected, [INT] integers - means this columns will only accept whole numbers, without any decimal.  We then create second column, [first_name], and specify it should be text ([VARCHAR] stands for \"variable characters\").  [255] here means that the value entered can't be more than 255 characters long.  And we do the same for [last_name], [role], and [team].  We declare [full_time] as a [BOOLEAN] Boolean, which is the type for logical values.  this column can only holds 0 or 1.  Then [office] is declared as [VARCHAR] as well because its text.  Data engineers then run other statements to update the table and write records into it.  \n",
    "\n",
    "[\n",
    "CREATE TABEL employees (\n",
    "    employee_id INT, \n",
    "    first_name VARCHAR(255), \n",
    "    last_name VARCHAR(255), \n",
    "    role VARCHAR(255), \n",
    "    team VARCHAR(255), \n",
    "    full_time BOOLEAN, \n",
    "    office VARCHAR(255)\n",
    "    )\n",
    "]\n",
    "\n",
    "# *******************************************************************************************************************\n",
    "Data scientists will then use SQL to query the table.  For example, if Julian wants to get the frst and last name of all the employee whose role title contains the keyword data, he can SELECT the first and last name, FROM the employees table, WHERE the role title contains \"Data\".  The percentage signs on each side of \"Data\" mean Data can appear anywherein the role title.  \n",
    "# *******************************************************************************************************************\n",
    "\n",
    "[\n",
    "SELECT first_name, last_name \n",
    "FROM employees\n",
    "WHERE role LIKE \"%Data%\"\n",
    "]\n",
    "\n",
    "So far, we've looked at tables individually; but databases are made of many tables.  The database schema governs how tables are related.  In the Spotflix's database, we have a table for [albums], containing columns for the album's unique ID, the artists unique ID, the title of the album, etc.  We also had an [artists] table, containing columns for the artist unique ID, the artist name and their biography.  The [artists] table can then be linked to the [alumns] table through the artist ID.  We also have a [songs] table with columns for the song unique ID, album ID, song title, track number, song length, etc.  The [songs] table can be linked to the [albums] table through album ID.  We alsohave a [playlists] table with columns for a playlist unique ID, the ID of the user that created it, the song ID, date added, position number, etc.  We can link the [playlists] table to the [songs] table through the song ID.  We could have other tables for labels, genres, users, etc.  See why these are called relational databases.  \n",
    "\n",
    "\n",
    "Finally, there are several implementations of SQL [SQLite, MySQL, PostgreSQL, Oracle SQL, SQL Server].  How they differ is out of the scope of this course, but they are pretty similar.  Switching from one to the other is like switching from QWERTY keyboard to an AZERTY one, or switching from British ENglish to American English.  A few things change, but most things stay the same.  \n",
    "\n",
    "\n",
    "\n",
    "You now understand why SQL s the langurage or reference for RDBMS, how data engineers and data scientists use it differently, can give you an example of a database schema, and can cite several QL implementations.  Time for some exercises.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd1df77-e0b6-4680-87cd-a2afd967a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu@debian:~$ cd ~/.virtual_environments/\n",
    "jhu@debian:~/.virtual_environments$ ls | grep *db\n",
    "test.db\n",
    "jhu@debian:~/.virtual_environments$ sqlite3 test.db \n",
    "SQLite version 3.34.1 2021-01-20 14:10:07\n",
    "Enter \".help\" for usage hints.\n",
    "sqlite> .databases\n",
    "main: /home/jhu/.virtual_environments/test.db r/w\n",
    "sqlite> .tables\n",
    "test_table\n",
    "sqlite> SELECT * FROM test_table LIMIT 5;\n",
    "10001|2|1023|100|12\n",
    "10001|2|1024|120|32\n",
    "10001|2|1023|100|24\n",
    "10001|2|1026|130|9\n",
    "10001|2|1025|128|32\n",
    "sqlite> .schema test_table    #######################################################################################\n",
    "CREATE TABLE test_table (\n",
    "\tseller_id BIGINT, \n",
    "\tcustomer_id BIGINT, \n",
    "\tproduct_id BIGINT, \n",
    "\tproduct_price BIGINT, \n",
    "\tproduct_quantity BIGINT\n",
    ");\n",
    "sqlite> SELECT * FROM test_table WHERE product_price LIKE \"%10%\";\n",
    "10001|2|1023|100|12\n",
    "10001|2|1023|100|24\n",
    "10003|2|3035|310|32\n",
    "sqlite> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19db03-66a0-4adf-a493-54b8f3a6ac77",
   "metadata": {},
   "source": [
    "## We can work it out\n",
    "\n",
    "Which language is the industry standard to create, update, maintain and query databases?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    English\n",
    "    1\n",
    "    Python\n",
    "    2\n",
    "#    SQL\n",
    "    3\n",
    "    JavaScript\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c040bc7-ba97-4b8d-9026-2ae6ab81b1f3",
   "metadata": {},
   "source": [
    "## Columns\n",
    "\n",
    "Which column allows these two tables to form a relational database?\n",
    "\n",
    "genres:\n",
    "    genre_id    #\n",
    "    genre_name\n",
    "    genre_superset\n",
    "    \n",
    "songs:\n",
    "    song_id\n",
    "    album_id\n",
    "    song_title\n",
    "    track_number\n",
    "    song_length\n",
    "    genre_id     #\n",
    "\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    The Column of Marcus Aurelius\n",
    "    1\n",
    "#    The genre_id column\n",
    "    2\n",
    "    The genre_name column\n",
    "    3\n",
    "    The genre_superset column\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68434f43-f4fb-4cd6-b4a4-e9901163402b",
   "metadata": {},
   "source": [
    "## Different breeds\n",
    "\n",
    "SQL is the industry standard for Relational Database Management System. In other words, it is to databases what English is to pop music.\n",
    "\n",
    "However, data engineers and data scientists don't use it the same way. Within the data science team at Spotflix, there are a few tasks that need to be assigned to either the data engineers or the data scientist. Can you help them do that?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Decide whether these tasks should be taken care of by data engineers or data scientist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347b37a-a528-4966-865e-d85962ba88d3",
   "metadata": {},
   "source": [
    "Data engineer:\n",
    "    Creating a new table to store the songs customers listened to the most over the past year\n",
    "    Updating an artists table after they edited their biography\n",
    "    Modifying the whole songs table to remove trailing space entered by mistake in front of the title\n",
    "    \n",
    "Data scientist:\n",
    "    Querying  the top songs of the past year to identify which genre dominated\n",
    "    Querying the artist table to find all the bands that come from France\n",
    "    QUerying the lyrics table to find all the songs that have \"data\" in title\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860fcbc2-aa57-46b4-88b2-e668ee310cbc",
   "metadata": {},
   "source": [
    "## Data warehouses and data lakes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  Now its time to clarify some concepts.  Remember the data pipelines lesson at the end of chapter 1.  We quickly mentioned [data lakes].  Along the course we also mentioned [databases] several times.  In the first lesson of the course, we mentioned [data warehouses].  So what are these and what is the difference.  \n",
    "\n",
    "Thats the topic of this lesson.  First, lets look at our data pipeline again.  \n",
    "\n",
    "\n",
    "                                                      / US\n",
    "                                        / sales dept -- UK\n",
    "                                       /             \\ Belgium\n",
    "Phone app  \\               / employees -- engineering dept\n",
    "            \\             /            \\  support dept\n",
    "             \\           / / customers\n",
    "              \\         // / playlists\n",
    "Desktop app -- Data lake --- tracks    -- -- -- -- \n",
    "              /              albums    -- album pictures\n",
    "             /               artists\n",
    "Website     /\n",
    "\n",
    "\n",
    "As the data pipeline graph shows, the [data lake] is  where all the collected raw data gets stored, just as it was uploaded from the different sources.  Its unprocessed and messy.  While the [data lake] stores all the data, the [data warehouse] stores specific data for a specific use.  For example, users and their subscription type, or all the listening sessions for behavioral analysis.  For this reason, a data lake can take petabytes of data, but a wharehouses are ususally small - small on the scale of big data.  It can still way bigger than your external hard drive.  \n",
    "\n",
    "A [data lake] can store any kind of data, whether its structured, semi-structured or unstructured.  This means that it does not enforce any model on the way to store the data.  This makes it cost-effective.  The [data wharehouse] enforce a structured format, which makes them more costly to manipulate.  However, this lake of structure also means its very difficult to analyze.  Some big data analytics using deep learning can be implemented to discover hidden patterns and trends, but thats about it, and should probably be last resort.  The [data wharehouse], on the othet hand, is optimized for analytics to drive business decisions.  Because no model is enforced in [data lake] and any structure can be stored, it is necessary to keep a data catalog up to date.  More on that in a seconds.  \n",
    "\n",
    "The [data lakes] are used by data scientists for real-time analytics on big data, while [data wharehouses] are used by analysts for ad-hoc, read-only queries like aggregation and summarization.  A [data catalog] is a source of truth that compensates for the lack of structure in a data lake.  Among other things, it [keeps track of where the data comes from, how is used, who is responsible for maintaining it, and how aften it gets updated].  Its good practice to have one in terms of [data governance] (managing the availability, usability, integrity and security of the data), and guarantees the reproducibility of the processes in case anything unexpected happens.  Or if someone want to reproduce an analysis from the very begining, starting with the ingestion of the data.  Because of the very flexible way data lakes store data, a data catalog is necessary to prevent the data lake becoming a data swamp.  \n",
    "\n",
    "Its good practice to have a data catalog referencing any data that moves through your organization, so that we don't have to rely on tribal knowledge, which makes us autonomous, and makes working with data more scalable.  We can go from finding data to preparing it without having to rely on a human source of information every time we have a question.  \n",
    "\n",
    "\n",
    "Lets take a step back.  We've used the term [database] throughout the course several times.  Where does it fit in.  Database is a very general term that can be loosely defined as organized data stored and accessed on a computer.  So once again, its a general term.  And a [data wharehouse] is a type of database.  \n",
    "\n",
    "\n",
    "\n",
    "Alright, now you know the characteristics of data lakes, data wharehouses and databases, how they differ, and why a data catalog is useful and necessary.  Let and this chapter by cementing your knowledg with a few exercises.  Then onwards to chapter 3 to learn more about moving and processing data.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2f1ac-110d-4c56-8c73-52f9dc1b17f5",
   "metadata": {},
   "source": [
    "## Tell the truth\n",
    "\n",
    "So far, you heard about data lakes, data warehouses, databases, and you just saw the differences between the three.\n",
    "\n",
    "Which of the following statements is true?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    A data catalog is a document listing the prices of different data storage services.\n",
    "    1\n",
    "#    A data warehouse is a type of database.\n",
    "    2\n",
    "    A relational database usually stores unstructured data.\n",
    "    3\n",
    "    The data lake stores well-organized, processed data that's easy to analyze.\n",
    "    4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4761c53-4c34-4b9a-918e-5de5250a72d2",
   "metadata": {},
   "source": [
    "## Our warehouse (in the middle of our street)\n",
    "\n",
    "Although both are used for data storage, data lakes and data warehouses are used for different purposes and work in different ways.\n",
    "\n",
    "Can you correctly classify the statements, depending on whether they apply to data lakes or data warehouses?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements: do they apply to data lakes or data warehouses?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6d776-04c5-4ecf-bead-1f66092656a7",
   "metadata": {},
   "source": [
    "A data lake:\n",
    "    Can store structured, semi-structured and structured data\n",
    "    Is mainly used by data scientists and engineers\n",
    "    Stores raw data\n",
    "    Is optimized for cost efficiency\n",
    "    \n",
    "    \n",
    "A data warehouse:\n",
    "    Usually stores smaller amounts of data than the other\n",
    "    Is optimized for analysis\n",
    "    Is mainly used by data analysts, business analysts, data scientists and machine learning engineers\n",
    "    Stores mainly structured data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab4eec3-77f9-42cf-81d4-09f7d9bf8b64",
   "metadata": {},
   "source": [
    "## Processing data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Welcome to third and final chapter.  Now we have a few idea of what data engineering is, and how data can be stored in different ways.  This chapter will cover the last step on our roadmap: moving and processing data.  Lets have a quick look at the pipeline again to build some intuition.  \n",
    "\n",
    "                                                      / US\n",
    "                                        / sales dept -- UK\n",
    "                                       /             \\ Belgium\n",
    "Phone app  \\               / employees -- engineering dept\n",
    "            \\             /            \\  support dept\n",
    "             \\           / / customers\n",
    "              \\         // / playlists\n",
    "Desktop app -- Data lake --- tracks    -- -- -- -- \n",
    "              /              albums    -- album pictures\n",
    "             /               artists\n",
    "Website     /\n",
    "\n",
    "\n",
    "When we move data to the data lake, when we split it into different tables, or when we remore corrupted tracks, we are [processing data].  So what does it mean to process data.  In a nutshell [data processing] consists in converting raw data into meaningful information.  Precisely why do we need to process data?  Well, there may be some data that we don't need at all.  When rolling out a new features, we may be watching a lot of indicators to ensure its working as expected.  But once we're sure its stable and well integrated, we don't need this data anymore.  Storing and processing data is not free, so we want to optimize our memory, process and network costs.  Uncompressed data can be 10 times larger than compressed one: imagine if we had to process that.  Our whole business model would collapse.  \n",
    "\n",
    "[Some data may come in a type, but would be easier to use in another].  \n",
    "For example, there is a tradeoff between file size and quality of the music tracks.  At Spotflix, artists may upload data in .wav or .flac format, which are high quality master files.  Letting users stream these big files would incur big network costs.  The data is processed by converting the master file to the .ogg format, a lighter format with a slightly lowers sound quality.  Its these files that we will stream to our users.  We want to move and organize data so it is easier for analysts to find what they need, like you saw on the data pipeline graph.  \n",
    "\n",
    "Music files also contain metadata, like the name of the artist and the genre.  [The data is again processed to extract the metadata and store it in a database, for easy access by data analysts and data scientists].  You may want your data to fit a certain schema or structure, to reap the benefits covered in the previous chapter.  We gather employee data and fit it to the specific table schema you saw with the employee table, separating name and last name, using logic instead of text to distinguish between part-time and full-time employees, etc.  \n",
    "\n",
    "[Data processing also increase productivity].  At Spotflix, we automate all the data preparation steps we can, so that when it arrives to data scientists, they can analyze it almost immediately.  The value they add to the company originates from the insights derived from their analyses, so we need to help them focus on and deliver exactly that.  \n",
    "\n",
    "In terms of [data processing], data engineers have different responsibilities.  They perform data manipulation, cleaning, and tidying tasks that can be automated and that will always need to be done, regardless of the analysis anyone wants to do with them.  For example, rejecting corrupt song files, or deciding what happens with missing metadata.  What should we do when the genre is missing?  Do we reject the file, do we leave the genre blank, or do we provide one by default?  They also ensure that the data is stored in a sanely structured database, and create views on top of the database tables for easy ccess by analysts.  Views are the output of a stored query on the data.  Fpr example, artist data and albumdata should be stored in separate tables in the database, but people will often want to work on these things together.  That means data engineers need to create a view in the database combining both tables.  Data engineers also optimize the performance of databases, for example by indexing the data so its easier to retrieve.  \n",
    "\n",
    "There are a bazillion data processing tools, but they are out of the scope of this course.  [Hadoop, Amazon EMR, Flink etc.]  One such tool is [Apache Spark], for which you can find courses on DataCamp if you're interested.  \n",
    "\n",
    "\n",
    "\n",
    "Alright, now you can tell what data processing is, why its necessary, what it consists in and how we process data at Spotflix.  Lets hammer the nail with some exercises.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b99fe12-8708-4425-9874-641f7ad7110e",
   "metadata": {},
   "source": [
    "## Connect the dots\n",
    "\n",
    "Data pipelines are used to process data. At the end of Chapter 1, you learned about ETL (Extract, Transform, Load), one of the frameworks used to build data pipelines. The data processing tasks you just studied actually match that framework, corresponding to either extraction, transformation or loading operations.\n",
    "\n",
    "Note that although saving and loading are usually considered to be opposites, in the context of data engineering, they are the same thing, as you may have noticed. The reason for this is that when you're saving something, you're just storing it in the next step in the pipeline.\n",
    "\n",
    "Can you correctly classify data processing tasks as extraction, transformation, or loading operations?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the operations as Extract, Transform or Load operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e2578-272a-45be-a67d-fe59f0dc2e51",
   "metadata": {},
   "source": [
    "Extract:\n",
    "    Pulling the top 20 songs users have been listening to on a loop\n",
    "    Collecting data from Google Analytics about our web-marketing promotion offering 3 months of access to the premium tier\n",
    "    \n",
    "Transform:\n",
    "    Writing all the followers of a user in a table  [load]\n",
    "    Summarizing the yearly listening activity to tell users how many hours they're listened to music on Spotflix this year\n",
    "    \n",
    "Load:\n",
    "    Saving the new order of a playlist that was sorted based on the data songs were added, so that it remains that way the next time the user connects\n",
    "    Sorting a palylist's songs based on the date they were added  [Transform]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dcc543-46ed-4d5e-a087-a9f61cefed19",
   "metadata": {},
   "source": [
    "## Scheduling data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Great job on these exercises.  Now that we understand the data processing, lets talk about scheduling.  Scheduling can apply to any task we listed in the previous data processing lesson.  \n",
    "\n",
    "In this lesson though, to demonstrate scheduling, we will focus on updating tables and databases to keep things straightforward and easy to understand.  The [scheduling is the glue of a data engineering system].  It holds each small piece and organizes how they work together, by running tasks in a specific order and resolving all dependencies correctly.  There are different ways to glue things together.  For example, we can run tasks manually.  If an employee is moving form the United States to Belgium, and therefore changing offices, someone can request an immediate update and we can update the table right away ourselves.  However, they are downsides with human dependencies.  Ideally, we'd like our pipeline to be automated as much as possible.  \n",
    "\n",
    "Automation is when you set some tasks to execute at a specific time or condition.  For example, we could update the employee table every morning at 6AM.  Even if a employee is added the previous day, then the change will be reflected in the morning.  Or, we could set some tasks to execute if a specific condition is met.  This is called sensor scheduling.  For example, we could update the departments table only if a new employee was added to the employees table.  There is really no reason to update otherwise.  This sounds like the best option but it requires having sensor always listening to see if something been added.  This requires more resourcesand may not be worth it in this case.  \n",
    "\n",
    "Manual and automated systems can also work together: if a user manually upgrades their subscription on the app, automated tasks need to propagate this information to other parts of the syatem, to unlock new features and update billing information.  [Another thing that matters is how the data is ingested].  Data can be ingested in batches, which means its sent by groups at apecific intervals.  [Batch processing] is often cheaper, because you can schedule it when resources aren't being used elsewhere, typically overnight.  For example, song uploaded by artists may be batched and sent together to the databases every ten minutes, updates to the employee table can be batched every morning at 6AM, and the revenue table used by the finance department can be updated overnight as well.  The data can also be [streamed processing], which means individual data records are sent to the pipeline as soon as they are updated.  For example, if a user signs up, they want to be able to use the services right away, so we need to write their profile to the database immediately.  Nowdays, its inconceivable for a user to wait 24 hours to be able to use a service they just signed up for.  \n",
    "\n",
    "Anothet example of batch vs stream processing would be offerline vs online listening.  If a user listens online, Spotflix can stream parts of the song one after the other.  If the user wants to save the song to listen offline, we need to batch all parts of the song together so they can save it.  There is a third option called real-time, used for example in fraud detection, but for the sake of simplification and because streaming is almost always real-time, we will consider them to be the same in this course.  \n",
    "\n",
    "\n",
    "Some tools for scheduling are Apache Airflow, or Luigi.  Alright Now you know what scheduling is, the different ways to set it up, the difference between batches and streams, how all of this is implemented at Spotflix, and a couple of tools used to schedule data engineering systems.  Lets check your understanding.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be391c3-4179-4706-b756-0cb9b850c220",
   "metadata": {},
   "source": [
    "## Schedules\n",
    "\n",
    "You just saw three ways of scheduling data: manually, at a specific time, or if a specific condition is met.\n",
    "\n",
    "Can you correctly classify the following actions?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Correctly classify the actions as being ran manually, at a specific time, or if a specific condition is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37e9d7-50ee-48d7-8d83-f2cfd3c0c536",
   "metadata": {},
   "source": [
    "Manual:\n",
    "    Running the song encoding pipeline, because engineering changed the encoder and wants to make sure they will pass the validation check\n",
    "    Running the pipeline processing sign ups because in the past 10 minutes, 100 new users complained to support that they can't connect\n",
    "    \n",
    "Time:\n",
    "    Generating the Spotflix weekly playlist from chapter 1 every monday at 00:00 AM\n",
    "    Collecting data from Google Analytics every morning to check how the promotion campaign is going\n",
    "    Processing music videos uploaded by artists every hour\n",
    "    \n",
    "Condition:\n",
    "    Running validation checks if new videos are being collected\n",
    "    Updating the number of followers in a playlist table after a user subscribed to it\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4616d-780e-4636-943e-5ab2c86d8812",
   "metadata": {},
   "source": [
    "## One or the other\n",
    "\n",
    "You've seen that data can be processed in batches (records are grouped and processed at intervals) or streams (records are sent individually right away).\n",
    "\n",
    "Can you correctly classify the following actions as being batched or streamed?\n",
    "\n",
    "Some of these are tricky, you may have to think twice! Don't worry if you don't get it right the first time. All that matters is that you get the difference between batches and streams, so if you make a mistake, make sure to read the orange feedback messages at the bottom left to understand why!\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Correctly classify the actions as being batched or streamed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f3b239-bfac-482f-94c6-92b279fd0f18",
   "metadata": {},
   "source": [
    "Batch:\n",
    "    Updating the count of followers in a playlist when a user subscribes to it  [Stream]\n",
    "    Loading new employees to Spotflix's employee table\n",
    "    \n",
    "    \n",
    "Stream:\n",
    "    Reducing access to premium features when someone unsubscribes   [Betch]\n",
    "    When a user listens to songs that are being recommendedin real time, loading his upvotes and downvoteson each song\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e3b23-7d74-40ad-a777-8bf608f67042",
   "metadata": {},
   "source": [
    "## Parallel computing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Good job.  Now, one term thats commonly used in data engineering is [parallel computing], sometimes also called [parallel processing].  Parallel computing forms the basic of almost all moden data processing tools.  It is important mainly for memory concerns, but also for processing power.  When big data processing tools perform a processing task, they split it up into several smaller subtasks.  These subtasks are then distributed over several computers.  Lets look at an analogy.  \n",
    "\n",
    "Lets say you're running a music merchandise shop and need to get a batch of 1000 t-shirts folded.  You senior sales assistant folds 100 shirts in 15 minutes.  Junior sales assistants typically take 30 minutes.  If just one sales assistant can work at a time, its obvious you'd have to choose the quickest one to finish the job.  However, if you can split the batch in 250 shirts each, having 4 junior employees working in parallel is is faster, they will finish in 1 hour and 15 minutes, when it would take 2 hours and 30 minutes for your senior employee to finish.  \n",
    "\n",
    "A similar thing happensfor big data processing tasks.  In this case, employees would be processing units.  One benefit of having multiple processing units is the [extra processing power] itself.  Another benefit of parallel computing for big data relates to [memory].  Instead of needing to load all of the data in one computer's memory, you can partition the data and load the subsets into memory of different computers.   That means the memory footprint peromputer is relatively small.  There can be some disadvantages to parallel computing though.  Moving data incurs cost.  Whats more, splitting a task into subtasks and merging the results of the subtasks back into one final result requires some communication between processes, which takes some additional time.  So if the gain of splitting into subtasks are minimal, it may not be worth taking that risk.  \n",
    "\n",
    "Going back to our t-shirt folding analogy, separating the t-shirt into 4 equal piles for each of the sales assistants may take 10 minutes, and collecting the 4 piles of folded t-shirt back together may take another 5 minutes.  SO it actually took them 1 hour and 30 minutes, instead of 1 hour and 15, to fold all the t-shirts.  \n",
    "\n",
    "At Spotflix, we use parallel computing to convert songs from lossless format to .ogg.  It prevents us from having to load all the new songs in one computer, and to benefit from extra processing power to run the conversion scripts.  \n",
    "\n",
    "\n",
    "\n",
    "Alright, now you know the benefits and risks of parallel computing, and how it is implemented at Spotflix.  Lets practice.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5e2c6c-d26b-4e31-9dc5-31da860417a7",
   "metadata": {},
   "source": [
    "## Whenever, whenever\n",
    "\n",
    "While you're having lunch with the rest of the data science team, Sasha, the new data engineer intern, is telling you this: \"Parallel computing is a jack of all trades and can be used whenever we want, for any task we want. It just optimizes running any data processing tasks. We should start implementing it across the whole pipeline. I'm ready to help doing it!\"\n",
    "\n",
    "Is her statement actually true or false?\n",
    "Answer the question\n",
    "50XP\n",
    "Possible Answers\n",
    "\n",
    "    True\n",
    "    1\n",
    "#    False\n",
    "    2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58204ba-4dad-4ac7-b922-5f94b88231a4",
   "metadata": {},
   "source": [
    "## Parallel universe\n",
    "\n",
    "You just told Sasha, the data engineer intern, that although incredibly efficient and powerful, parallel computing is not suited to every situation. It has its limitations, and sometimes it's just unnecessary.\n",
    "\n",
    "You would like to help Sasha improve her understanding. You ask her to share her assumptions about parallel computing: you will tell her if she's right or wrong, and try to explain why. Are you up to the challenge?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements as either right or wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3057af-4283-474e-a594-5f355140cc56",
   "metadata": {},
   "source": [
    "Right:\n",
    "    Parallel computing is used to provide extra processing power\n",
    "    Parallel computing relies on processing units\n",
    "    Its a good idea to use parallel computing to encode songs uploaded by artists to the .ogg format that Spotflix prefers\n",
    "    \n",
    "Wrong:\n",
    "    Parallel computing will always make things faster\n",
    "    Its a good idea to use parallel computing to update the employees table every morning\n",
    "    Parallel computing can't be used to optimize for memory usage\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fd992-7505-45d0-bb17-32e6f2bf50f8",
   "metadata": {},
   "source": [
    "## Cloud computing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Alright, this is the final stretch.  Let now talk about cloud computing.  Companies can process data in their own data center, often on premises.  We can imagine racks of servers, ready to be used, that the company has to buy.  We also need a room to store them, and if we move offices, we have to transport servers without losing service.  The electrical bill and maintenance would be at the company's cost.  Moreover, data processing tasks can be more or less intense, and don't happen continuously.  Companies would need to provide enough processing power for peak moments, and at quieter times, much of the processing power would remain unused.  Its avoiding this waste of resources that makes cloud computing so appearling.  \n",
    "\n",
    "In the cloud, we rent servers, and the rent is cheap: we dont get the same discount from our server salesperson that Amazon.  We dont need a room to store them, and we use the resources we need, at the time we need them.  Many companies moved to cloud as a way of cost optimization.  Also, the closer the server is to the user, the less latency they will experience when using our application.   To serve a global customer base, we need servers all over the world.  Another reason for using cloud computing is database reliability.  Runnng a data-critical company, we have to prepare for the worst.  A file can break out in an on-premises data center.  To be safe, we need to replicate our data at a different geographical location.  \n",
    "\n",
    "However, if your company manipulates sensitive or confidential data, there is a risk associated with someone else hosting it, and government surveillance.  With the advent of big data, companies specializing in these kinds of issues, called cloud providers, were born.  The 3 big players, in decreasing order of market share, are [Amazon Web Services 32.4%], [Microsoft Azure 17.6%], and [Google Cloud 6%].  For file storage, their respective services are [AWS S3], [Azure Blob Storage], and [Google Cloud Storage].  For computation, ther are [AWS EC2], [Azure Virtual Machines], and [Google Compute Engine].  And for databases, they are [AWS RDS], [Azure SQL Database], and [Google Cloud SQL].  Spotflix choose AWS, so we use S3 to store cover albums, EC2 to process songs, and RDS to store employees information.  \n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "                     File storage               Computation                   Databases\n",
    "AWS                  AWS S3                     AWS EC2                       AWS RDS\n",
    "\n",
    "Microsoft Azure      Azure Blob Storage         Azure Virtual Machines        Azure SQL Database\n",
    "\n",
    "Google Cloud         Google Cloud Storage       Google Compute Engine         Google Cloud SQL\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "You dont need to take all your cloud services from the same provider though.  You can use several ones: its called multicloud.  It has some advantages, like reducing reliance a single vendor.  It also optimizes costs, and might be necessary because of local laws.  It also allows you to militate against disasters.  For example, in 2017, AWS had an outage, which broke the internet: among other companies impacted half of the top hundred retaliers were down.  I mean, even isitdownrightnow.com was down.  Spotflix wasn't impacted in the end, because, well it doesn't exist.  \n",
    "\n",
    "Companies that had some redundancy with other providers could mitigate the impact.  However, cloud providers try to lock in consumers, by integrating as many of their services as they can.  Some services form one provider may not be compatible with services from another one, so that's something to be careful about.  It also makes managing security and governance harder.  \n",
    "\n",
    "\n",
    "\n",
    "Alright, now you know the benefits and risks or cloud computing, and how it is implemented at Spotflix.  You can also cite the main cloud providers and their respective ervices.  Home stretch with some exercises, and then I will tell you where to find the playlist, as promised at the end of chapter 1.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fedfb-20f1-4f2d-a393-a8098598aab4",
   "metadata": {},
   "source": [
    "## Obscured by clouds\n",
    "\n",
    "Sasha, the new data engineer intern, is now trying to convince you that cloud computing and multicloud computing have absolutely no downsides. You disagree: you know for a fact that this is not true. It makes you question whether or not she is actually comfortable with the topic.\n",
    "\n",
    "Once again, you take your manager role to heart and try to help her improve her understanding. You ask her to share her assumptions about cloud computing: you will tell her if she's right or wrong, and try to explain why. Are you up to the challenge?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Classify the statements as either right or wrong.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9f795-df3a-4647-a5ee-8deaa9b69257",
   "metadata": {},
   "source": [
    "Right:\n",
    "    Leveraging the cloud instead of having our own on-premises data center allows us to use just the resources we need, when we need them\n",
    "    Cloud computing encompasses storage, database and computing solutions\n",
    "    A milticloud solution reduce reliance on a single vendor\n",
    "    \n",
    "    \n",
    "Wrong:\n",
    "    Multicloud solutions reduce security and governance concerns\n",
    "    Cloud computing reduces all kinds of risk\n",
    "    EC2, S3 and RDS are solution offered by Microsoft Azure\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f40ae-ffc2-4115-a48d-e81510bdd990",
   "metadata": {},
   "source": [
    "## Somewhere I belong\n",
    "\n",
    "81% of companies have implemented a multicloud approach, according to Gartner. Spotflix's data engineers are worried about the company's reliance on a single vendor, and are considering a multicloud approach. They also think it might allow Spotflix to reduce costs, and to be more resilient in the face of a disaster.\n",
    "\n",
    "As you've just seen, the main cloud providers are AWS, Microsoft Azure and Google Cloud. Together, they own about half of the cloud computing market share. They have different services, some you saw in the video, some you're about to discover. They also have competitors, some of which you're about to discover as well.\n",
    "\n",
    "Can you help the data engineers classify the different services before they start evaluating alternatives?\n",
    "Instructions\n",
    "100XP\n",
    "\n",
    "Correctly classify the cloud services solutions as either storage, computing or databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4d756-9090-4bff-9ede-31cd5f4258fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "File storage:\n",
    "    AWS S3\n",
    "    IBM Cloud File Storage\n",
    "    \n",
    "    \n",
    "Computing:\n",
    "    AWS EC2\n",
    "    Azure Virtual Machine\n",
    "    \n",
    "    \n",
    "Databases:\n",
    "    Snowflake Data Warehouse\n",
    "    Google Cloud Datastore (NoSQL)\n",
    "    AWS Redshift (data warehouse)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f16ba8-a1b8-4808-95e8-83505b11a7f9",
   "metadata": {},
   "source": [
    "## We are the champions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Alright.  You paid your dues time after time, and bad mistakes, you may have made a few, but you've come through and reached the end of the course.  You've leanred a lot of things.  \n",
    "\n",
    "From the 1st chapter, you can now define data engineering, understand how important it is, explain how data engineers differ from data scientists, and how data pipelines ensure the data flows efficiently through an organization.  \n",
    "\n",
    "From the 2ed chapter, you can now cite the different structures data can take, and their pros and cons.  You also understand why SQL is fundamental in data engineering, and can explain the differences between data lakes, data warehouses and databases.  \n",
    "\n",
    "From the 3rd chapter, you can now explain what data processing consists in, and scheduling holds the data processing tasks together.  You also understand parallel computing and cloud computing.  \n",
    "\n",
    "\n",
    "You also learned a few other things, like what SQL code actually looks like, the main tools and technologies used in data engineering, and some more.  Last but not least, built a quite nice pipeline together.  On the right of the cource page at the bottom, you will find a section called datasets.  This is where we usually put the datasets of our data science programming courses.  Instead you will find a lexicon of all the technical terms covered in this course, that you an download if you want.  Finally, a promise is a promise.  At the end of chapter 1, I told you that all the exercise names in this course are actually song titles, and that if you made it through the end I would let you know where to find the corresponding playlist.  So if you go on Spotify and search for \"datachamp\", you will have access to it.  \n",
    "\n",
    "\n",
    "I hope you have a better understanding of data engineering, and that you had as much fun going through the course than I had creating it.  Congratulations on completing Data Engineering for Everyone, and thank you for taking it.  Best of luck in your next endeavors.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a07873e-5aea-493e-95cd-354f77ba023e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90199442-ee63-4ba4-a192-a6275cf92e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162a9a6-3b54-45f3-97ea-40fd7e275972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174621a-0908-4450-8e6d-3623761b6a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acf45c4-cd7c-4de4-b94a-c6a9c1e1f3e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f0257f-2824-4026-b9bd-8aa59fae231d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27138239-e7a8-4f19-819f-995e9072f08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7160d5-53c2-4fe9-9d08-5d50bc27beb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de816026-3757-4abb-87f5-1971d883ce60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e05b0-309f-49cf-8455-12943b6a23b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32faf4-39e0-437d-8147-f0ec8b7ae9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc81a997-e2c2-47c0-9b84-4b8a0fc2c30e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be14951-2cc5-47e7-b805-d5e0ce80f4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ee394-0433-4a1f-93a2-0d0ab3ee46da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ca9c3b-864d-447b-81e7-5bd749d30fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
